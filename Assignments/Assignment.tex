\documentclass[a4paper,12pt]{article}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{amsmath}
\newcommand{\matr}[1]{\mathbf{#1}}
\newcommand{\lik}{\mathcal{L}}

\title{Regression Computation Assignment}
\author{}
\date{}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

\vspace{-5em}

\maketitle

\vspace{-3em}

{\begin{center}\textit{\textbf{The assignment is due on Thursday June 4 at 23:59.}}\end{center}}

{\onehalfspacing



\section*{Purpose and Overview}

The purpose of this assignment is for you to demonstrate your understanding of the mathematics and computational procedures involved in the estimation of basic regression models. Below are several regression models. The first two (\texttt{m1} and \texttt{m2}) are OLS models explaining life expectancy and the latter two (\texttt{m3} and \texttt{m4}) are logistic regression models explaining democracy. All data are drawn from the Quality of Government Basic Dataset. The data and codebook are available here: \url{http://qog.pol.gu.se/data/datadownloads/qogbasicdata}.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{d} \hlkwb{<-} \hlstd{rio}\hlopt{::}\hlkwd{import}\hlstd{(}\hlstr{"http://www.qogdata.pol.gu.se/data/qog_bas_cs_jan15.csv"}\hlstd{)}

\hlstd{f1} \hlkwb{<-} \hlstd{une_leb} \hlopt{~} \hlkwd{I}\hlstd{(gle_cgdpc}\hlopt{/}\hlnum{1e4}\hlstd{)} \hlopt{+} \hlkwd{I}\hlstd{(ross_oil_netexpc}\hlopt{/}\hlnum{1e3}\hlstd{)}
\hlstd{m1} \hlkwb{<-} \hlkwd{lm}\hlstd{(f1,} \hlkwc{data} \hlstd{= d)}

\hlstd{f2} \hlkwb{<-} \hlstd{une_leb} \hlopt{~} \hlkwd{I}\hlstd{(gle_cgdpc}\hlopt{/}\hlnum{1e4}\hlstd{)}\hlopt{*}\hlkwd{factor}\hlstd{(chga_demo)} \hlopt{+}
                \hlkwd{I}\hlstd{(ross_oil_netexpc}\hlopt{/}\hlnum{1e3}\hlstd{)} \hlopt{+} \hlkwd{factor}\hlstd{(ht_colonial)}
\hlstd{m2} \hlkwb{<-} \hlkwd{lm}\hlstd{(f2,} \hlkwc{data} \hlstd{= d)}

\hlstd{f3} \hlkwb{<-} \hlstd{chga_demo} \hlopt{~} \hlstd{al_ethnic}
\hlstd{m3} \hlkwb{<-} \hlkwd{glm}\hlstd{(f3,} \hlkwc{data} \hlstd{= d,} \hlkwc{family} \hlstd{=} \hlkwd{binomial}\hlstd{(}\hlkwc{link}\hlstd{=}\hlstr{'logit'}\hlstd{))}

\hlstd{f4} \hlkwb{<-} \hlstd{chga_demo} \hlopt{~} \hlstd{al_ethnic} \hlopt{+} \hlkwd{I}\hlstd{(}\hlkwd{log}\hlstd{(wdi_landarea))} \hlopt{+}
                  \hlkwd{I}\hlstd{(gle_cgdpc}\hlopt{/}\hlnum{1e4}\hlstd{)} \hlopt{+} \hlkwd{I}\hlstd{(ross_oil_netexpc}\hlopt{/}\hlnum{1e3}\hlstd{)}
\hlstd{m4} \hlkwb{<-} \hlkwd{glm}\hlstd{(f4,} \hlkwc{data} \hlstd{= d,} \hlkwc{family} \hlstd{=} \hlkwd{binomial}\hlstd{(}\hlkwc{link}\hlstd{=}\hlstr{'logit'}\hlstd{))}
\end{alltt}
\end{kframe}
\end{knitrout}

\vspace{1em}
\noindent Your task is to reproduce parts of these analyses using R (or Stata), without the use of the \texttt{lm}, \texttt{glm}, \texttt{lm.fit}, or similar ready-made functions (or, for Stata, without the use of \texttt{reg}, \texttt{logit}, \texttt{glm}, or similar commands). The instructions below outline the code you should produce. You may use R (based on techniques from lecture) or Stata (for relevant technical details on Stata, see Ch. 11 and Appendix A from Cameron and Trivedi 2010).
}

\section*{Submitting Your Assignment}

\noindent Submit your assignment via email to Thomas (\url{mailto:tleeper@ps.au.dk}) in the form of a single, complete R syntax file (.R) or Stata (.do) file in your submitted assignment. Each step of the code should be numbered and labeled (in the form of a R or Stata comment) according to the numbering of the steps below. You do not need to explain, describe, or present the output of any analyses.


\clearpage

\doublespacing

\begin{enumerate}

\section*{Ordinary Least Squares Regression}

\item Construct a design matrix $\matr{X}$ for \texttt{m1}. Extract the $\matr{R}$ matrix from the $\matr{Q}\matr{R}$ decomposition of $\matr{X}$. Write code to produce this matrix using the formula given in class for the inverse of a 3-by-3 matrix.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Design matrix}
\hlstd{dat} \hlkwb{<-} \hlkwd{cbind}\hlstd{(}\hlnum{1}\hlstd{, d}\hlopt{$}\hlstd{gle_cgdpc}\hlopt{/}\hlnum{1e4}\hlstd{, d}\hlopt{$}\hlstd{ross_oil_netexpc}\hlopt{/}\hlnum{1e3}\hlstd{)}
\hlstd{cc} \hlkwb{<-} \hlkwd{complete.cases}\hlstd{(dat)}
\hlstd{X} \hlkwb{<-} \hlstd{dat[cc,]}

\hlcom{# QR decomposition}
\hlstd{QR} \hlkwb{<-} \hlkwd{qr}\hlstd{(X)}
\hlstd{R} \hlkwb{<-} \hlkwd{qr.R}\hlstd{(QR)}
\hlstd{R}

\hlcom{# inverse of the R matrix, manually}
\hlkwd{matrix}\hlstd{(}\hlkwd{c}\hlstd{(R[}\hlnum{2}\hlstd{,}\hlnum{2}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{3}\hlstd{,}\hlnum{3}\hlstd{]} \hlopt{-} \hlstd{R[}\hlnum{2}\hlstd{,}\hlnum{3}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{3}\hlstd{,}\hlnum{2}\hlstd{],}
         \hlopt{-}\hlstd{(R[}\hlnum{2}\hlstd{,}\hlnum{1}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{3}\hlstd{,}\hlnum{3}\hlstd{]} \hlopt{-} \hlstd{R[}\hlnum{2}\hlstd{,}\hlnum{3}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{3}\hlstd{,}\hlnum{1}\hlstd{]),}
         \hlstd{R[}\hlnum{2}\hlstd{,}\hlnum{1}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{3}\hlstd{,}\hlnum{2}\hlstd{]} \hlopt{-} \hlstd{R[}\hlnum{2}\hlstd{,}\hlnum{2}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{3}\hlstd{,}\hlnum{1}\hlstd{],}
         \hlopt{-}\hlstd{(R[}\hlnum{1}\hlstd{,}\hlnum{2}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{3}\hlstd{,}\hlnum{3}\hlstd{]} \hlopt{-} \hlstd{R[}\hlnum{1}\hlstd{,}\hlnum{3}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{3}\hlstd{,}\hlnum{2}\hlstd{]),}
         \hlstd{R[}\hlnum{1}\hlstd{,}\hlnum{1}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{3}\hlstd{,}\hlnum{3}\hlstd{]} \hlopt{-} \hlstd{R[}\hlnum{1}\hlstd{,}\hlnum{3}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{3}\hlstd{,}\hlnum{1}\hlstd{],}
         \hlopt{-}\hlstd{(R[}\hlnum{1}\hlstd{,}\hlnum{1}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{3}\hlstd{,}\hlnum{2}\hlstd{]} \hlopt{-} \hlstd{R[}\hlnum{1}\hlstd{,}\hlnum{2}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{3}\hlstd{,}\hlnum{1}\hlstd{]),}
         \hlstd{R[}\hlnum{1}\hlstd{,}\hlnum{2}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{2}\hlstd{,}\hlnum{3}\hlstd{]} \hlopt{-} \hlstd{R[}\hlnum{1}\hlstd{,}\hlnum{3}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{2}\hlstd{,}\hlnum{2}\hlstd{],}
         \hlopt{-}\hlstd{(R[}\hlnum{1}\hlstd{,}\hlnum{1}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{2}\hlstd{,}\hlnum{3}\hlstd{]} \hlopt{-} \hlstd{R[}\hlnum{1}\hlstd{,}\hlnum{3}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{2}\hlstd{,}\hlnum{1}\hlstd{]),}
         \hlstd{R[}\hlnum{1}\hlstd{,}\hlnum{1}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{2}\hlstd{,}\hlnum{2}\hlstd{]} \hlopt{-} \hlstd{R[}\hlnum{1}\hlstd{,}\hlnum{2}\hlstd{]} \hlopt{*} \hlstd{R[}\hlnum{2}\hlstd{,}\hlnum{1}\hlstd{]),} \hlkwc{nrow} \hlstd{=} \hlnum{3}\hlstd{)} \hlopt{*} \hlstd{(}\hlnum{1}\hlopt{/}\hlkwd{det}\hlstd{(R))}

\hlcom{# check inverse of the R matrix, automatically}
\hlkwd{solve}\hlstd{(R)}
\end{alltt}
\end{kframe}
\end{knitrout}

\item Create a vector \texttt{y} to represent the outcome. Then construct an appropriate design matrix $\matr{X}$ for \texttt{m2} (as represented by formula \texttt{f2}) from the original variables in the dataset, including the specified categorical (factor) variables and interaction term (see Fox pp.153--155). Note: Be careful handling missing values!

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# define `y`}
\hlstd{y} \hlkwb{<-} \hlstd{d}\hlopt{$}\hlstd{une_leb}

\hlcom{# call `model.matrix` directly to create design matrix:}
\hlstd{X} \hlkwb{<-} \hlkwd{model.matrix}\hlstd{(f2,} \hlkwc{data} \hlstd{= d)}

\hlcom{# manual alternative:}
\hlstd{x1} \hlkwb{<-} \hlstd{d}\hlopt{$}\hlstd{gle_cgdpc}\hlopt{/}\hlnum{10000}
\hlstd{x2} \hlkwb{<-} \hlstd{d}\hlopt{$}\hlstd{chga_demo}
\hlstd{x3} \hlkwb{<-} \hlstd{x1}\hlopt{*}\hlstd{x2}
\hlstd{x4} \hlkwb{<-} \hlstd{d}\hlopt{$}\hlstd{ross_oil_netexpc}\hlopt{/}\hlnum{1000}
\hlstd{u} \hlkwb{<-} \hlkwd{sort}\hlstd{(}\hlkwd{unique}\hlstd{(d}\hlopt{$}\hlstd{ht_colonial))}
\hlstd{x5} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlnum{NA}\hlstd{,} \hlkwc{nrow} \hlstd{=} \hlkwd{nrow}\hlstd{(d),} \hlkwc{ncol} \hlstd{=} \hlkwd{length}\hlstd{(u))}
\hlkwa{for}\hlstd{(i} \hlkwa{in} \hlkwd{seq_along}\hlstd{(u)) \{}
    \hlstd{x5[,i]} \hlkwb{<-} \hlkwd{as.numeric}\hlstd{(d}\hlopt{$}\hlstd{ht_colonial} \hlopt{==} \hlstd{u[i])}
\hlstd{\}}
\hlstd{dat} \hlkwb{<-} \hlkwd{cbind}\hlstd{(y,} \hlnum{1}\hlstd{, x1, x2, x3, x4, x5)}
\hlstd{cc} \hlkwb{<-} \hlkwd{complete.cases}\hlstd{(dat)}
\hlstd{X} \hlkwb{<-} \hlstd{dat[cc,} \hlopt{-}\hlnum{1}\hlstd{]}
\hlkwd{colnames}\hlstd{(X)} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlstr{'Intercept'}\hlstd{,} \hlstr{'gle_cgdpc'}\hlstd{,} \hlstr{'chga_demo'}\hlstd{,}
                 \hlstr{'gle_cgdpc*chga_demo'}\hlstd{,} \hlstr{'ross_oil_netexpc'}\hlstd{,}
                 \hlkwd{paste0}\hlstd{(}\hlstr{'ht_colonial'}\hlstd{, u))}
\hlcom{# drop linearly dependent columns}
\hlstd{X} \hlkwb{<-} \hlstd{X[,} \hlopt{!}\hlkwd{colnames}\hlstd{(X)} \hlopt{%in%} \hlkwd{c}\hlstd{(}\hlstr{'ht_colonial0'}\hlstd{,} \hlstr{'ht_colonial9'}\hlstd{)]}

\hlcom{# pass complete cases to `y`}
\hlstd{y} \hlkwb{<-} \hlstd{dat[cc,} \hlnum{1}\hlstd{]}
\end{alltt}
\end{kframe}
\end{knitrout}


\item Estimate the Ordinary Least Squares (OLS) coefficients in \texttt{m2} using matrix notation (see Fox p.155). You may use a QR decomposition if you so choose.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# using standard matrix notation (X'X)^\{-1\}X'y}
\hlstd{beta} \hlkwb{<-} \hlkwd{solve}\hlstd{(}\hlkwd{t}\hlstd{(X)} \hlopt{%*%} \hlstd{X)} \hlopt{%*%} \hlkwd{t}\hlstd{(X)} \hlopt{%*%} \hlstd{y}
\hlstd{beta}

\hlcom{# using a QR decomposition}
\hlstd{decomp} \hlkwb{<-} \hlkwd{qr}\hlstd{(X)}
\hlstd{beta} \hlkwb{<-} \hlkwd{solve}\hlstd{(}\hlkwd{qr.R}\hlstd{(decomp))} \hlopt{%*%} \hlkwd{t}\hlstd{(}\hlkwd{qr.Q}\hlstd{(decomp))} \hlopt{%*%} \hlstd{y}
\hlstd{beta}
\end{alltt}
\end{kframe}
\end{knitrout}

\item Obtain the fitted values (where $\matr{\hat{y}} = \matr{X}\matr{\hat{\beta}}$), from model \texttt{m2} with all variables held at their observed values, except:

\begin{itemize}
\item \texttt{gle\_cgdpc} = 10000
\item \texttt{chga\_demo} = 1
\item \texttt{ross\_oil\_netexpc} = 1000
\item \texttt{ht\_colonial} = 0
\end{itemize}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{Xtmp} \hlkwb{<-} \hlstd{X}
\hlstd{Xtmp[,}\hlstr{'gle_cgdpc'}\hlstd{]} \hlkwb{<-} \hlnum{10000}
\hlstd{Xtmp} \hlopt{%*%} \hlstd{beta}

\hlstd{Xtmp} \hlkwb{<-} \hlstd{X}
\hlstd{Xtmp[,}\hlstr{'chga_demo'}\hlstd{]} \hlkwb{<-} \hlnum{1}
\hlstd{Xtmp} \hlopt{%*%} \hlstd{beta}

\hlstd{Xtmp} \hlkwb{<-} \hlstd{X}
\hlstd{Xtmp[,}\hlstr{'ross_oil_netexpc'}\hlstd{]} \hlkwb{<-} \hlnum{1000}
\hlstd{Xtmp} \hlopt{%*%} \hlstd{beta}

\hlstd{Xtmp} \hlkwb{<-} \hlstd{X}
\hlcom{# redefine all `ht_colonial` columns:}
\hlstd{Xtmp[,}\hlkwd{grepl}\hlstd{(}\hlstr{'ht_colonial'}\hlstd{,}\hlkwd{colnames}\hlstd{(Xtmp))]} \hlkwb{<-} \hlnum{0}
\hlcom{# or manually:}
\hlstd{Xtmp[,}\hlstr{'ht_colonial1'}\hlstd{]} \hlkwb{<-} \hlnum{0}
\hlstd{Xtmp[,}\hlstr{'ht_colonial2'}\hlstd{]} \hlkwb{<-} \hlnum{0}
\hlstd{Xtmp[,}\hlstr{'ht_colonial3'}\hlstd{]} \hlkwb{<-} \hlnum{0}
\hlstd{Xtmp[,}\hlstr{'ht_colonial4'}\hlstd{]} \hlkwb{<-} \hlnum{0}
\hlstd{Xtmp[,}\hlstr{'ht_colonial5'}\hlstd{]} \hlkwb{<-} \hlnum{0}
\hlstd{Xtmp[,}\hlstr{'ht_colonial6'}\hlstd{]} \hlkwb{<-} \hlnum{0}
\hlstd{Xtmp[,}\hlstr{'ht_colonial7'}\hlstd{]} \hlkwb{<-} \hlnum{0}
\hlstd{Xtmp[,}\hlstr{'ht_colonial8'}\hlstd{]} \hlkwb{<-} \hlnum{0}
\hlcom{#Xtmp[,'ht_colonial9'] <- 0 # dropped previously}
\hlstd{Xtmp[,}\hlstr{'ht_colonial10'}\hlstd{]} \hlkwb{<-} \hlnum{0}
\hlstd{Xtmp} \hlopt{%*%} \hlstd{beta}
\end{alltt}
\end{kframe}
\end{knitrout}

\item Estimate the variance-covariance matrix of the OLS coefficient estimates for \texttt{m2} and extract estimated standard errors from that matrix (see Fox p.158).

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{fitted} \hlkwb{<-} \hlstd{X} \hlopt{%*%} \hlstd{beta}
\hlstd{e} \hlkwb{<-} \hlstd{fitted} \hlopt{-} \hlstd{y}
\hlstd{df} \hlkwb{<-} \hlkwd{nrow}\hlstd{(X)} \hlopt{-} \hlkwd{length}\hlstd{(beta)}
\hlstd{s2} \hlkwb{<-} \hlstd{(}\hlkwd{t}\hlstd{(e)} \hlopt{%*%} \hlstd{e)} \hlopt{/} \hlstd{df}

\hlcom{# variance-covariance matrix}
\hlstd{V} \hlkwb{<-} \hlkwd{as.numeric}\hlstd{(s2)} \hlopt{*} \hlkwd{solve}\hlstd{(}\hlkwd{t}\hlstd{(X)} \hlopt{%*%} \hlstd{X)}

\hlcom{# standard errors}
\hlkwd{sqrt}\hlstd{(}\hlkwd{diag}\hlstd{(V))}
\end{alltt}
\end{kframe}
\end{knitrout}

\item Use the estimated coefficients and standard errors for \texttt{m2} to obtain the \textit{t}-statistics for each coefficient estimate under a null hypothesis $H_0: \beta_k = 0$ (see Fox 3.3 and 4.4). Calculate the one-tailed and two-tailed p-values for each test statistic using the \texttt{pt} function, which returns the value of Student's \textit{t} cumulative distribution function.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{tstats} \hlkwb{<-} \hlstd{beta}\hlopt{/}\hlkwd{sqrt}\hlstd{(}\hlkwd{diag}\hlstd{(V))}

\hlcom{# determine degrees of freedom for t-test}
\hlstd{ndf} \hlkwb{<-} \hlkwd{nrow}\hlstd{(X)} \hlopt{-} \hlkwd{length}\hlstd{(beta)}

\hlcom{# one-tailed test (two alternative strategies)}
\hlnum{1}\hlopt{-}\hlkwd{pt}\hlstd{(}\hlkwd{abs}\hlstd{(tstats), ndf)}
\hlkwd{pt}\hlstd{(}\hlopt{-}\hlkwd{abs}\hlstd{(tstats), ndf)}

\hlcom{# two-tailed test (two alternative strategies)}
\hlnum{2}\hlopt{*}\hlstd{(}\hlnum{1}\hlopt{-}\hlkwd{pt}\hlstd{(}\hlkwd{abs}\hlstd{(tstats), ndf))}
\hlnum{2}\hlopt{*}\hlkwd{pt}\hlstd{(}\hlopt{-}\hlkwd{abs}\hlstd{(tstats), ndf)}
\end{alltt}
\end{kframe}
\end{knitrout}


\clearpage
\section*{Logistic Regression}

\item Represent the log-likelihood function for logistic regression as an R (or Stata) function (see Fox 3.6). Recall the general structure of the log-likelihood for a binary outcome variable is: 
\begin{align*}
\ln\lik(\beta) = \sum_{i=1}^{n} y_i \ln(\pi_i) + (1-y_i) \ln(1-\pi_i)
\end{align*}
where $\pi_i$ in the logistic model is given by the inverse link function $\dfrac{e^{\matr{X}_i\beta}}{1 + e^{\matr{X}_i\beta}}$.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{logitll} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{beta}\hlstd{,} \hlkwc{y}\hlstd{,} \hlkwc{X}\hlstd{)\{}
  \hlstd{p} \hlkwb{<-} \hlkwd{exp}\hlstd{(X} \hlopt{%*%} \hlstd{beta)}\hlopt{/}\hlstd{(}\hlnum{1}\hlopt{+}\hlkwd{exp}\hlstd{(X} \hlopt{%*%} \hlstd{beta))}
  \hlstd{lik} \hlkwb{<-} \hlstd{y} \hlopt{*} \hlkwd{log}\hlstd{(p)} \hlopt{+} \hlstd{(}\hlnum{1}\hlopt{-}\hlstd{y)} \hlopt{*} \hlkwd{log}\hlstd{(}\hlnum{1}\hlopt{-}\hlstd{p)}
  \hlkwd{sum}\hlstd{(lik)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}


\item Estimate the coefficients for \texttt{m3} using two methods of maximum likelihood estimation: (a) a grid search and (b) an optimization algorithm implemented by \texttt{optim}. For the grid search, search for possible slope and intercept coefficients in the range between -5 and +5.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{dat} \hlkwb{<-} \hlkwd{cbind}\hlstd{(d}\hlopt{$}\hlstd{chga_demo,}\hlnum{1}\hlstd{,d}\hlopt{$}\hlstd{al_ethnic)}
\hlstd{cc} \hlkwb{<-} \hlkwd{complete.cases}\hlstd{(dat)}
\hlstd{Xm3} \hlkwb{<-} \hlstd{dat[cc,}\hlnum{2}\hlopt{:}\hlnum{3}\hlstd{]}
\hlstd{ym3} \hlkwb{<-} \hlstd{dat[cc,}\hlnum{1}\hlstd{]}

\hlcom{# grid search (could be more precise)}
\hlstd{iseq} \hlkwb{<-} \hlkwd{seq}\hlstd{(}\hlopt{-}\hlnum{5}\hlstd{,} \hlnum{5}\hlstd{,} \hlkwc{by} \hlstd{=} \hlnum{0.025}\hlstd{)}
\hlstd{sseq} \hlkwb{<-} \hlkwd{seq}\hlstd{(}\hlopt{-}\hlnum{5}\hlstd{,} \hlnum{5}\hlstd{,} \hlkwc{by} \hlstd{=} \hlnum{0.025}\hlstd{)}
\hlstd{g} \hlkwb{<-} \hlkwd{expand.grid}\hlstd{(}\hlkwc{intercept} \hlstd{= iseq,} \hlkwc{slope} \hlstd{= sseq)}
\hlstd{gs} \hlkwb{<-} \hlkwd{apply}\hlstd{(g,} \hlnum{1}\hlstd{,} \hlkwa{function}\hlstd{(}\hlkwc{z}\hlstd{)} \hlkwd{logitll}\hlstd{(}\hlkwc{beta} \hlstd{= z,} \hlkwc{X} \hlstd{= Xm3,} \hlkwc{y} \hlstd{= ym3))}
\hlstd{g[}\hlkwd{which.max}\hlstd{(gs), ]}

\hlcom{# optimization algorithm}
\hlstd{optm3} \hlkwb{<-} \hlkwd{optim}\hlstd{(}\hlkwc{par} \hlstd{=} \hlkwd{rep}\hlstd{(}\hlnum{0}\hlstd{,} \hlnum{2}\hlstd{),}
               \hlkwc{fn} \hlstd{= logitll,}
               \hlkwc{X} \hlstd{= Xm3,}
               \hlkwc{y} \hlstd{= ym3,}
               \hlkwc{control} \hlstd{=} \hlkwd{list}\hlstd{(}\hlkwc{fnscale} \hlstd{=} \hlopt{-}\hlnum{1}\hlstd{),}
               \hlkwc{hessian} \hlstd{=} \hlnum{TRUE}\hlstd{,}
               \hlkwc{method} \hlstd{=} \hlstr{"BFGS"}\hlstd{)}
\hlstd{optm3}\hlopt{$}\hlstd{par}
\end{alltt}
\end{kframe}
\end{knitrout}

\item Estimate the standard errors for coefficient estimates in \texttt{m3} using bootstrapping. 

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# function to estimate model one time}
\hlstd{once} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{X}\hlstd{,} \hlkwc{y}\hlstd{) \{}
    \hlstd{opt} \hlkwb{<-} \hlkwd{optim}\hlstd{(}\hlkwc{par} \hlstd{=} \hlkwd{rep}\hlstd{(}\hlnum{0}\hlstd{,} \hlnum{2}\hlstd{),}
                 \hlkwc{fn} \hlstd{= logitll,}
                 \hlkwc{X} \hlstd{= X,}
                 \hlkwc{y} \hlstd{= y,}
                 \hlkwc{control} \hlstd{=} \hlkwd{list}\hlstd{(}\hlkwc{fnscale} \hlstd{=} \hlopt{-}\hlnum{1}\hlstd{),}
                 \hlkwc{hessian} \hlstd{=} \hlnum{TRUE}\hlstd{,}
                 \hlkwc{method} \hlstd{=} \hlstr{"BFGS"}\hlstd{)}
    \hlstd{opt}\hlopt{$}\hlstd{par}
\hlstd{\}}

\hlcom{# bootstrap}
\hlstd{n} \hlkwb{<-} \hlnum{5000}
\hlstd{bootmat} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlkwd{numeric}\hlstd{(),} \hlkwc{ncol} \hlstd{=} \hlnum{2}\hlstd{,} \hlkwc{nrow} \hlstd{= n)}
\hlkwa{for}\hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlstd{n) \{}
    \hlstd{s} \hlkwb{<-} \hlkwd{sample}\hlstd{(}\hlnum{1}\hlopt{:}\hlkwd{nrow}\hlstd{(X),} \hlkwd{nrow}\hlstd{(X),} \hlnum{TRUE}\hlstd{)}
    \hlstd{Xtmp} \hlkwb{<-} \hlstd{Xm3[s,]}
    \hlstd{ytmp} \hlkwb{<-} \hlstd{ym3[s]}
    \hlstd{tried} \hlkwb{<-} \hlkwd{try}\hlstd{(}\hlkwd{once}\hlstd{(Xtmp, ytmp))}
    \hlkwa{if}\hlstd{(}\hlopt{!}\hlkwd{inherits}\hlstd{(tried,} \hlstr{'try-error'}\hlstd{))}
        \hlstd{bootmat[i,]} \hlkwb{<-} \hlstd{tried}
\hlstd{\}}
\hlkwd{apply}\hlstd{(bootmat,} \hlnum{2}\hlstd{, sd,} \hlkwc{na.rm} \hlstd{=} \hlnum{TRUE}\hlstd{)}

\hlcom{# jackknife (just for fun)}
\hlstd{jackmat} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlkwd{numeric}\hlstd{(),} \hlkwc{ncol} \hlstd{=} \hlnum{2}\hlstd{,} \hlkwc{nrow} \hlstd{=} \hlkwd{nrow}\hlstd{(X))}
\hlkwa{for}\hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlkwd{nrow}\hlstd{(X)) \{}
    \hlstd{Xtmp} \hlkwb{<-} \hlstd{Xm3[}\hlopt{-}\hlstd{i,]}
    \hlstd{ytmp} \hlkwb{<-} \hlstd{ym3[}\hlopt{-}\hlstd{i]}
    \hlstd{tried} \hlkwb{<-} \hlkwd{try}\hlstd{(}\hlkwd{once}\hlstd{(Xtmp, ytmp))}
    \hlkwa{if}\hlstd{(}\hlopt{!}\hlkwd{inherits}\hlstd{(tried,} \hlstr{'try-error'}\hlstd{))}
        \hlstd{jackmat[i,]} \hlkwb{<-} \hlstd{tried}
\hlstd{\}}
\hlkwd{apply}\hlstd{(jackmat,} \hlnum{2}\hlstd{, sd,} \hlkwc{na.rm} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\item Obtain 95\% bootstrap confidence intervals for the \texttt{m3} coefficient estimates from the bootstrap distribution of the coefficients.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{t}\hlstd{(}\hlkwd{apply}\hlstd{(bootmat,} \hlnum{2}\hlstd{, quantile,} \hlkwc{probs} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0.025}\hlstd{,}\hlnum{0.975}\hlstd{),} \hlkwc{na.rm} \hlstd{=} \hlnum{TRUE}\hlstd{))}
\end{alltt}
\end{kframe}
\end{knitrout}

\item Estimate the coefficients for \texttt{m4} using \texttt{optim}, obtain the standard errors as the diagonal of the matrix inverse of the negative hessian matrix, calculate the $z$-statistic for each coefficient estimate, and determine its two-tailed p-value from \texttt{pnorm} (the normal cumulative distribution function).

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{dat} \hlkwb{<-} \hlkwd{cbind}\hlstd{(d}\hlopt{$}\hlstd{chga_demo,}\hlnum{1}\hlstd{,d}\hlopt{$}\hlstd{al_ethnic,} \hlkwd{log}\hlstd{(d}\hlopt{$}\hlstd{wdi_landarea),}
             \hlstd{d}\hlopt{$}\hlstd{gle_cgdpc}\hlopt{/}\hlnum{1e4}\hlstd{, d}\hlopt{$}\hlstd{ross_oil_netexpc}\hlopt{/}\hlnum{1e3}\hlstd{)}
\hlstd{cc} \hlkwb{<-} \hlkwd{complete.cases}\hlstd{(dat)}
\hlstd{Xm4} \hlkwb{<-} \hlstd{dat[cc,}\hlopt{-}\hlnum{1}\hlstd{]}
\hlstd{ym4} \hlkwb{<-} \hlstd{dat[cc,}\hlnum{1}\hlstd{]}

\hlstd{optm4} \hlkwb{<-} \hlkwd{optim}\hlstd{(}\hlkwc{par} \hlstd{=} \hlkwd{rep}\hlstd{(}\hlnum{0}\hlstd{,} \hlnum{5}\hlstd{),}
               \hlkwc{fn} \hlstd{= logitll,}
               \hlkwc{X} \hlstd{= Xm4,}
               \hlkwc{y} \hlstd{= ym4,}
               \hlkwc{control} \hlstd{=} \hlkwd{list}\hlstd{(}\hlkwc{fnscale} \hlstd{=} \hlopt{-}\hlnum{1}\hlstd{),}
               \hlkwc{hessian} \hlstd{=} \hlnum{TRUE}\hlstd{,}
               \hlkwc{method} \hlstd{=} \hlstr{"BFGS"}\hlstd{)}

\hlcom{# coefficient estimates}
\hlstd{optm4}\hlopt{$}\hlstd{par}

\hlcom{# standard errors}
\hlkwd{sqrt}\hlstd{(}\hlkwd{diag}\hlstd{(}\hlkwd{solve}\hlstd{(}\hlopt{-}\hlstd{optm4}\hlopt{$}\hlstd{hessian)))}

\hlcom{# z-statistics}
\hlstd{zstats} \hlkwb{<-} \hlstd{optm4}\hlopt{$}\hlstd{par}\hlopt{/}\hlkwd{sqrt}\hlstd{(}\hlkwd{diag}\hlstd{(}\hlkwd{solve}\hlstd{(}\hlopt{-}\hlstd{optm4}\hlopt{$}\hlstd{hessian)))}
\hlstd{zstats}

\hlcom{# two-tailed p-values (two alternative strategies)}
\hlnum{2}\hlopt{*}\hlstd{(}\hlnum{1}\hlopt{-}\hlkwd{pnorm}\hlstd{(}\hlkwd{abs}\hlstd{(zstats)))}
\hlnum{2}\hlopt{*}\hlkwd{pnorm}\hlstd{(}\hlopt{-}\hlkwd{abs}\hlstd{(zstats))}
\end{alltt}
\end{kframe}
\end{knitrout}


\item Using your estimated coefficients for \texttt{m3} and \texttt{m4}, compute the \textit{average} predicted probability of observing the outcome when \texttt{al\_ethnic} is set to each of the five-number summary quantiles $(0.00, 0.25, 0.50, 0.75, 1.00)$ of the observed distribution of \texttt{al\_ethnic} and all other covariates are held at their observed values. Your results should be two vectors, one for each model, each containing five numbers.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# function to compute predicted probabilities}
\hlstd{pp} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{dat}\hlstd{,} \hlkwc{coefvec}\hlstd{) \{}
    \hlkwd{mean}\hlstd{(}\hlkwd{exp}\hlstd{(dat} \hlopt{%*%} \hlstd{coefvec)}\hlopt{/}\hlstd{(}\hlnum{1}\hlopt{+}\hlkwd{exp}\hlstd{(dat} \hlopt{%*%} \hlstd{coefvec)))}
\hlstd{\}}
\hlstd{qs} \hlkwb{<-} \hlkwd{quantile}\hlstd{(d}\hlopt{$}\hlstd{al_ethnic,} \hlkwd{c}\hlstd{(}\hlnum{0.00}\hlstd{,}\hlnum{0.25}\hlstd{,}\hlnum{0.50}\hlstd{,}\hlnum{0.75}\hlstd{,}\hlnum{1.00}\hlstd{),} \hlkwc{na.rm} \hlstd{=} \hlnum{TRUE}\hlstd{)}

\hlcom{# m3}
\hlstd{Xm3tmp} \hlkwb{<-} \hlstd{Xm3}
\hlstd{m3out} \hlkwb{<-} \hlkwd{numeric}\hlstd{(}\hlnum{5}\hlstd{)}
\hlkwa{for}\hlstd{(i} \hlkwa{in} \hlkwd{seq_along}\hlstd{(qs)) \{}
    \hlstd{Xm3tmp[,}\hlnum{2}\hlstd{]} \hlkwb{<-} \hlstd{qs[i]}
    \hlstd{m3out[i]} \hlkwb{<-} \hlkwd{pp}\hlstd{(}\hlkwc{dat} \hlstd{= Xm3tmp,} \hlkwc{coefvec} \hlstd{= optm3}\hlopt{$}\hlstd{par)}
\hlstd{\}}
\hlstd{m3out}

\hlcom{# m4}
\hlstd{Xm4tmp} \hlkwb{<-} \hlstd{Xm4}
\hlstd{m4out} \hlkwb{<-} \hlkwd{numeric}\hlstd{(}\hlnum{5}\hlstd{)}
\hlkwa{for}\hlstd{(i} \hlkwa{in} \hlkwd{seq_along}\hlstd{(qs)) \{}
    \hlstd{Xm4tmp[,}\hlnum{2}\hlstd{]} \hlkwb{<-} \hlstd{qs[i]}
    \hlstd{m4out[i]} \hlkwb{<-} \hlkwd{pp}\hlstd{(}\hlkwc{dat} \hlstd{= Xm4tmp,} \hlkwc{coefvec} \hlstd{= optm4}\hlopt{$}\hlstd{par)}
\hlstd{\}}
\hlstd{m4out}
\end{alltt}
\end{kframe}
\end{knitrout}


\end{enumerate}


\end{document}
